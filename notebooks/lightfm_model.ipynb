{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b39d41a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import json\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "import optuna\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from lightfm.evaluation import precision_at_k\n",
    "import os\n",
    "\n",
    "# Default path to data files\n",
    "PATH = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccec6192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating\n",
       "0      196      242       3\n",
       "1      186      302       3\n",
       "2       22      377       1\n",
       "3      244       51       2\n",
       "4      166      346       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load user-item interaction data\n",
    "interaction_data = pd.read_csv(\n",
    "    PATH + 'ml-100k/u.data',\n",
    "    sep='\\t',\n",
    "    encoding=\"latin1\",\n",
    "    names=['user_id', 'item_id', 'rating', 'timestamp']\n",
    "    )[['user_id', 'item_id', 'rating']]\n",
    "display(interaction_data.shape)\n",
    "interaction_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db06c50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1', ['age:24', 'gender:M', 'occupation:technician', 'zipcode:85'])\n",
      "('2', ['age:53', 'gender:F', 'occupation:other', 'zipcode:94'])\n",
      "('3', ['age:23', 'gender:M', 'occupation:writer', 'zipcode:32'])\n",
      "('4', ['age:24', 'gender:M', 'occupation:technician', 'zipcode:43'])\n",
      "('5', ['age:33', 'gender:F', 'occupation:other', 'zipcode:15'])\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a defaultdict to hold user features\n",
    "user_data = defaultdict(dict)\n",
    "\n",
    "# Read data and build user features dictionary\n",
    "def load_feature(file_path, feature_name):\n",
    "    with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            userId = row['userId']\n",
    "            value = row[feature_name]\n",
    "            user_data[userId][feature_name] = value\n",
    "\n",
    "# Load each feature file\n",
    "load_feature(PATH + 'ageRel.csv', 'age')\n",
    "load_feature(PATH + 'genderRel.csv', 'gender')\n",
    "load_feature(PATH + 'occupationRel.csv', 'occupation')\n",
    "load_feature(PATH + 'residesRel.csv', 'zipcode')\n",
    "\n",
    "# Build user features list\n",
    "user_features_raw = [\n",
    "    (userId, [f'age:{data[\"age\"]}', f'gender:{data[\"gender\"]}', f'occupation:{data[\"occupation\"]}', f'zipcode:{data[\"zipcode\"]}'])\n",
    "    for userId, data in user_data.items()\n",
    "]\n",
    "\n",
    "# Display first 5 user features\n",
    "for item in user_features_raw[:5]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20b9aca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2', ['releaseDate:Jan-1995', 'genre:Action', 'genre:Adventure', 'genre:Thriller'])\n",
      "('4', ['releaseDate:Jan-1995', 'genre:Action', 'genre:Comedy', 'genre:Drama'])\n",
      "('17', ['releaseDate:Feb-1996', 'genre:Action', 'genre:Comedy', 'genre:Crime', 'genre:Horror', 'genre:Thriller'])\n",
      "('21', ['releaseDate:Feb-1996', 'genre:Action', 'genre:Adventure', 'genre:Comedy', 'genre:Musical', 'genre:Thriller'])\n",
      "('22', ['releaseDate:Feb-1996', 'genre:Action', 'genre:Drama', 'genre:War'])\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a defaultdict to hold item features\n",
    "item_data = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "# Read data and build item features dictionary\n",
    "# Modified version to handle multiple genres\n",
    "def load_feature(file_path, feature_name):\n",
    "    with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            itemId = row['movieId']\n",
    "            value = row[feature_name]\n",
    "            if feature_name == 'genreDesc':\n",
    "                item_data[itemId]['genre'].append(value)\n",
    "            else:\n",
    "                item_data[itemId][feature_name] = value\n",
    "\n",
    "# Load each feature file\n",
    "load_feature(PATH + 'releaseRel.csv', 'releaseDate')\n",
    "load_feature(PATH + 'genreRel.csv', 'genreDesc')\n",
    "\n",
    "# Build item features list\n",
    "item_features_raw = [\n",
    "    (\n",
    "        itemId,\n",
    "        [f'releaseDate:{data[\"releaseDate\"]}'] +\n",
    "        [f'genre:{genre}' for genre in data['genre']]\n",
    "    )\n",
    "    for itemId, data in item_data.items()\n",
    "]\n",
    "\n",
    "# Display first 5 item features\n",
    "for item in item_features_raw[:5]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6969351e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items on test set: 30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['159', '458', '679', '128', '658']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load test item IDs from the json file saved\n",
    "# previously from Knowledge Graph Method\n",
    "with open('../experiments/test_ids.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "# Extract test item IDs as integers\n",
    "test_item_ids = [item['movieId'] for item in data]\n",
    "print(f\"items on test set: {len(test_item_ids)}\")\n",
    "display(test_item_ids[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42ddacae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets for later evaluation\n",
    "# with LightFM the same way as done in Knowledge Graph Method\n",
    "\n",
    "# Interaction data for training (excluding test items)\n",
    "train_interactions_df = interaction_data[\n",
    "    ~interaction_data['item_id'].astype(str).isin(test_item_ids)]\n",
    "# Interaction data for testing (only test items)\n",
    "test_interactions_df = interaction_data[\n",
    "    interaction_data['item_id'].astype(str).isin(test_item_ids)]\n",
    "\n",
    "# Item side features for training (only users in train interactions)\n",
    "train_item_features = [item for item in item_features_raw if item[0] not in test_item_ids]\n",
    "# Item side features for testing (only testing items)\n",
    "test_item_features = [item for item in item_features_raw if item[0] in test_item_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ce4cca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build lightfm Dataset\n",
    "dataset = Dataset()\n",
    "\n",
    "# User and Items unique ids from training interactions\n",
    "train_user_ids = train_interactions_df['user_id'].astype(str).unique()\n",
    "train_item_ids = train_interactions_df['item_id'].astype(str).unique()\n",
    "\n",
    "# Unique features from user and item features\n",
    "user_feature_set = set(f for _, feats in user_features_raw for f in feats)\n",
    "item_feature_set = set(f for _, feats in train_item_features for f in feats)\n",
    "\n",
    "# Partial fit\n",
    "dataset.fit(\n",
    "    users=train_user_ids,\n",
    "    items=train_item_ids,\n",
    "    user_features=user_feature_set,\n",
    "    item_features=item_feature_set\n",
    ")\n",
    "\n",
    "# Build training matrices\n",
    "(interactions, weights) = dataset.build_interactions(\n",
    "    [(str(row['user_id']), str(row['item_id']), row['rating']) for _, row in train_interactions_df.iterrows()]\n",
    ")\n",
    "\n",
    "user_features = dataset.build_user_features(user_features_raw)\n",
    "item_features = dataset.build_item_features(train_item_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ed60c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement hiperparameter tuning using Optuna\n",
    "# to find the best parameters for LightFM model\n",
    "\n",
    "# Define the objective function for optimization\n",
    "def objective(trial):\n",
    "    # Hiperparâmetros a otimizar\n",
    "    no_components = trial.suggest_int('no_components', 20, 100)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n",
    "    loss = trial.suggest_categorical('loss', ['logistic'])\n",
    "\n",
    "    # Validação cruzada: média de N splits\n",
    "    n_splits = 3\n",
    "    scores = []\n",
    "\n",
    "    for _ in range(n_splits):\n",
    "        # Split data into train and validation sets\n",
    "        train, valid = random_train_test_split(\n",
    "            interactions, test_percentage=0.2)\n",
    "        \n",
    "        # Instantiate and train the model\n",
    "        model = LightFM(\n",
    "            no_components=no_components,\n",
    "            learning_rate=learning_rate,\n",
    "            loss=loss\n",
    "        )\n",
    "\n",
    "        model.fit(\n",
    "            train,\n",
    "            user_features=user_features,\n",
    "            item_features=item_features,\n",
    "            epochs=20,\n",
    "            num_threads=4\n",
    "        )\n",
    "\n",
    "        # Evaluate the model using precision@k\n",
    "        score = precision_at_k(\n",
    "            model,\n",
    "            valid,\n",
    "            k=5,\n",
    "            user_features=user_features,\n",
    "            item_features=item_features\n",
    "        ).mean()\n",
    "        scores.append(score)\n",
    "        \n",
    "    return sum(scores) / len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e7ccd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the optimization with Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best parameters found:\")\n",
    "print(study.best_params)\n",
    "\n",
    "# Save the best parameters to a JSON file\n",
    "os.makedirs(\"../experiments\", exist_ok=True)\n",
    "with open(\"../experiments/lightfm_best_params.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"best_params\": study.best_params,\n",
    "            \"best_precision_at_5\": study.best_value\n",
    "        },\n",
    "        f,\n",
    "        indent=4\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kgenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
