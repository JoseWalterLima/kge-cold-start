{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b39d41a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import json\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "import optuna\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from lightfm.evaluation import precision_at_k\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Default path to data files\n",
    "PATH = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccec6192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000209, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating\n",
       "0        1     1193       5\n",
       "1        1      661       3\n",
       "2        1      914       3\n",
       "3        1     3408       4\n",
       "4        1     2355       5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load user-item interaction data\n",
    "interaction_data = pd.read_csv(\n",
    "    PATH + 'ml-1m/ratings.dat',\n",
    "    sep='::',\n",
    "    names=['user_id', 'item_id', 'rating', 'timestamp']\n",
    "    )[['user_id', 'item_id', 'rating']]\n",
    "display(interaction_data.shape)\n",
    "interaction_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db06c50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1', ['age:1', 'gender:F', 'occupation:10', 'zipcode:48'])\n",
      "('2', ['age:56', 'gender:M', 'occupation:16', 'zipcode:70'])\n",
      "('3', ['age:25', 'gender:M', 'occupation:15', 'zipcode:55'])\n",
      "('4', ['age:45', 'gender:M', 'occupation:7', 'zipcode:02'])\n",
      "('5', ['age:25', 'gender:M', 'occupation:20', 'zipcode:55'])\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a defaultdict to hold user features\n",
    "user_data = defaultdict(dict)\n",
    "\n",
    "# Read data and build user features dictionary\n",
    "def load_feature(file_path, feature_name):\n",
    "    with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            userId = row['userId']\n",
    "            value = row[feature_name]\n",
    "            user_data[userId][feature_name] = value\n",
    "\n",
    "# Load each feature file\n",
    "load_feature(PATH + 'ageRel.csv', 'age')\n",
    "load_feature(PATH + 'genderRel.csv', 'gender')\n",
    "load_feature(PATH + 'occupationRel.csv', 'occupation')\n",
    "load_feature(PATH + 'residesRel.csv', 'zipcode')\n",
    "\n",
    "# Build user features list\n",
    "user_features_raw = [\n",
    "    (userId, [f'age:{data[\"age\"]}', f'gender:{data[\"gender\"]}',\n",
    "              f'occupation:{data[\"occupation\"]}', f'zipcode:{data[\"zipcode\"]}'])\n",
    "    for userId, data in user_data.items()\n",
    "]\n",
    "\n",
    "# Display first 5 user features\n",
    "for item in user_features_raw[:5]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20b9aca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1', ['releaseDate:1995', 'genre:Animation', \"genre:Children's\", 'genre:Comedy'])\n",
      "('2', ['releaseDate:1995', 'genre:Adventure', \"genre:Children's\", 'genre:Fantasy'])\n",
      "('3', ['releaseDate:1995', 'genre:Comedy', 'genre:Romance'])\n",
      "('4', ['releaseDate:1995', 'genre:Comedy', 'genre:Drama'])\n",
      "('5', ['releaseDate:1995', 'genre:Comedy'])\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a defaultdict to hold item features\n",
    "item_data = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "# Read data and build item features dictionary\n",
    "# Modified version to handle multiple genres\n",
    "def load_feature(file_path, feature_name):\n",
    "    with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            itemId = row['movieId']\n",
    "            value = row[feature_name]\n",
    "            if feature_name == 'genreDesc':\n",
    "                item_data[itemId]['genre'].append(value)\n",
    "            else:\n",
    "                item_data[itemId][feature_name] = value\n",
    "\n",
    "# Load each feature file\n",
    "load_feature(PATH + 'releaseRel.csv', 'releaseDate')\n",
    "load_feature(PATH + 'genreRel.csv', 'genreDesc')\n",
    "\n",
    "# Build item features list\n",
    "item_features_raw = [\n",
    "    (\n",
    "        itemId,\n",
    "        [f'releaseDate:{data[\"releaseDate\"]}'] +\n",
    "        [f'genre:{genre}' for genre in data['genre']]\n",
    "    )\n",
    "    for itemId, data in item_data.items()\n",
    "]\n",
    "\n",
    "# Manter apenas filmes que foram assitidos por pelo menos um usuário\n",
    "valid_item_ids = set(interaction_data['item_id'].astype(str).unique())\n",
    "item_features_raw = [\n",
    "    (item_id, features) for item_id, features in item_features_raw if item_id in valid_item_ids\n",
    "]\n",
    "\n",
    "# Display first 5 item features\n",
    "for item in item_features_raw[:5]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6969351e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items on test set: 297\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['3408', '2687', '3186', '2762', '3114']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load test item IDs from the json file saved\n",
    "# previously from Knowledge Graph Method\n",
    "with open('../experiments/test_ids.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "# Extract test item IDs as integers\n",
    "test_item_ids = [item['movieId'] for item in data]\n",
    "print(f\"items on test set: {len(test_item_ids)}\")\n",
    "display(test_item_ids[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42ddacae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets for later evaluation\n",
    "# with LightFM the same way as done in Knowledge Graph Method\n",
    "\n",
    "# Interaction data for training (excluding test items)\n",
    "# Remover todas as interações dos itens de teste permite\n",
    "# simular o cenário de recomendação de novos itens\n",
    "train_interactions_df = interaction_data[\n",
    "    ~interaction_data['item_id'].astype(str).isin(test_item_ids)]\n",
    "\n",
    "# Interaction data for testing (only test items)\n",
    "# Usado na etapa de avaliação como ground truth\n",
    "test_interactions_df = interaction_data[\n",
    "    interaction_data['item_id'].astype(str).isin(test_item_ids)]\n",
    "\n",
    "# Item side features for testing (only testing items)\n",
    "test_item_features = [item for item in item_features_raw if item[0] in test_item_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ce4cca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build lightfm Dataset\n",
    "dataset = Dataset()\n",
    "\n",
    "# All unique user and item ids because LightFM needs all ids\n",
    "# even if some items are only in the test set\n",
    "user_ids = interaction_data['user_id'].astype(str).unique()\n",
    "# Os itens em cold start precisam estar no dataset\n",
    "item_ids = interaction_data['item_id'].astype(str).unique()\n",
    "\n",
    "# Unique features from user and item features\n",
    "user_feature_set = set(f for _, feats in user_features_raw for f in feats)\n",
    "item_feature_set = set(f for _, feats in item_features_raw for f in feats)\n",
    "\n",
    "# Partial fit\n",
    "dataset.fit(\n",
    "    users=user_ids,\n",
    "    items=item_ids,\n",
    "    user_features=user_feature_set,\n",
    "    item_features=item_feature_set\n",
    ")\n",
    "\n",
    "# Build training matrices considering only training interactions\n",
    "# so its possible to simulate cold-start for items in the test set\n",
    "(interactions, weights) = dataset.build_interactions(\n",
    "    [(str(row['user_id']), str(row['item_id']), row['rating']) for _, row in train_interactions_df.iterrows()]\n",
    ")\n",
    "\n",
    "user_features = dataset.build_user_features(user_features_raw)\n",
    "item_features = dataset.build_item_features(item_features_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ed60c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement hiperparameter tuning using Optuna\n",
    "# to find the best parameters for LightFM model\n",
    "\n",
    "# Define the objective function for optimization\n",
    "def objective(trial):\n",
    "    # Hiperparâmetros a otimizar\n",
    "    no_components = trial.suggest_int('no_components', 20, 100)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n",
    "    loss = trial.suggest_categorical('loss', ['logistic'])\n",
    "\n",
    "    # Validação cruzada: média de N splits\n",
    "    n_splits = 3\n",
    "    scores = []\n",
    "\n",
    "    for _ in range(n_splits):\n",
    "        # Split data into train and validation sets\n",
    "        train, valid = random_train_test_split(\n",
    "            interactions, test_percentage=0.2)\n",
    "        \n",
    "        # Instantiate and train the model\n",
    "        model = LightFM(\n",
    "            no_components=no_components,\n",
    "            learning_rate=learning_rate,\n",
    "            loss=loss\n",
    "        )\n",
    "\n",
    "        model.fit(\n",
    "            train,\n",
    "            user_features=user_features,\n",
    "            item_features=item_features,\n",
    "            epochs=20,\n",
    "            num_threads=4\n",
    "        )\n",
    "\n",
    "        # Evaluate the model using precision@k\n",
    "        score = precision_at_k(\n",
    "            model,\n",
    "            valid,\n",
    "            k=5,\n",
    "            user_features=user_features,\n",
    "            item_features=item_features\n",
    "        ).mean()\n",
    "        scores.append(score)\n",
    "        \n",
    "    return sum(scores) / len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1e7ccd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-26 14:35:22,009] A new study created in memory with name: no-name-218d7300-a34e-4152-b744-cfd6c688551f\n",
      "[I 2025-10-26 14:49:02,978] Trial 0 finished with value: 0.018090691417455673 and parameters: {'no_components': 43, 'learning_rate': 0.0419953200687935, 'loss': 'logistic'}. Best is trial 0 with value: 0.018090691417455673.\n",
      "[I 2025-10-26 15:12:27,852] Trial 1 finished with value: 0.017053134739398956 and parameters: {'no_components': 79, 'learning_rate': 0.00013054210973122946, 'loss': 'logistic'}. Best is trial 0 with value: 0.018090691417455673.\n",
      "[I 2025-10-26 15:19:41,410] Trial 2 finished with value: 0.021899228915572166 and parameters: {'no_components': 23, 'learning_rate': 0.03906730044605027, 'loss': 'logistic'}. Best is trial 2 with value: 0.021899228915572166.\n",
      "[I 2025-10-26 15:46:52,879] Trial 3 finished with value: 0.022384539246559143 and parameters: {'no_components': 92, 'learning_rate': 0.027653258787099663, 'loss': 'logistic'}. Best is trial 3 with value: 0.022384539246559143.\n",
      "[I 2025-10-26 16:03:17,173] Trial 4 finished with value: 0.01922505348920822 and parameters: {'no_components': 55, 'learning_rate': 0.010318560454640711, 'loss': 'logistic'}. Best is trial 3 with value: 0.022384539246559143.\n",
      "[I 2025-10-26 16:17:42,970] Trial 5 finished with value: 0.01760675758123398 and parameters: {'no_components': 48, 'learning_rate': 0.00022868548573110148, 'loss': 'logistic'}. Best is trial 3 with value: 0.022384539246559143.\n",
      "[I 2025-10-26 16:46:35,913] Trial 6 finished with value: 0.016542553901672363 and parameters: {'no_components': 99, 'learning_rate': 0.06517710840837866, 'loss': 'logistic'}. Best is trial 3 with value: 0.022384539246559143.\n",
      "[I 2025-10-26 17:11:25,794] Trial 7 finished with value: 0.017256861552596092 and parameters: {'no_components': 85, 'learning_rate': 0.0005148914586825069, 'loss': 'logistic'}. Best is trial 3 with value: 0.022384539246559143.\n",
      "[I 2025-10-26 17:34:43,856] Trial 8 finished with value: 0.016786154359579086 and parameters: {'no_components': 80, 'learning_rate': 0.00020913971528826824, 'loss': 'logistic'}. Best is trial 3 with value: 0.022384539246559143.\n",
      "[I 2025-10-26 17:42:56,507] Trial 9 finished with value: 0.017244039103388786 and parameters: {'no_components': 27, 'learning_rate': 0.002390646023152761, 'loss': 'logistic'}. Best is trial 3 with value: 0.022384539246559143.\n",
      "[I 2025-10-26 18:03:09,085] Trial 10 finished with value: 0.021506816148757935 and parameters: {'no_components': 69, 'learning_rate': 0.008931439214032775, 'loss': 'logistic'}. Best is trial 3 with value: 0.022384539246559143.\n",
      "[I 2025-10-26 18:10:16,360] Trial 11 finished with value: 0.02001841552555561 and parameters: {'no_components': 23, 'learning_rate': 0.018741586601580946, 'loss': 'logistic'}. Best is trial 3 with value: 0.022384539246559143.\n",
      "[I 2025-10-26 18:21:17,117] Trial 12 finished with value: 0.01711612567305565 and parameters: {'no_components': 37, 'learning_rate': 0.09050092402887921, 'loss': 'logistic'}. Best is trial 3 with value: 0.022384539246559143.\n",
      "[I 2025-10-26 18:49:54,547] Trial 13 finished with value: 0.017230020835995674 and parameters: {'no_components': 99, 'learning_rate': 0.0034799994634381673, 'loss': 'logistic'}. Best is trial 3 with value: 0.022384539246559143.\n",
      "[I 2025-10-26 19:07:33,887] Trial 14 finished with value: 0.018020281568169594 and parameters: {'no_components': 61, 'learning_rate': 0.031149535202811756, 'loss': 'logistic'}. Best is trial 3 with value: 0.022384539246559143.\n",
      "[I 2025-10-26 19:25:37,736] Trial 15 finished with value: 0.017092609778046608 and parameters: {'no_components': 62, 'learning_rate': 0.00316095049094586, 'loss': 'logistic'}. Best is trial 3 with value: 0.022384539246559143.\n",
      "[I 2025-10-26 19:36:00,438] Trial 16 finished with value: 0.023545121774077415 and parameters: {'no_components': 35, 'learning_rate': 0.01606289377288433, 'loss': 'logistic'}. Best is trial 16 with value: 0.023545121774077415.\n",
      "[I 2025-10-26 19:46:24,654] Trial 17 finished with value: 0.023394761607050896 and parameters: {'no_components': 35, 'learning_rate': 0.009403968897077907, 'loss': 'logistic'}. Best is trial 16 with value: 0.023545121774077415.\n",
      "[I 2025-10-26 19:56:12,316] Trial 18 finished with value: 0.016844041645526886 and parameters: {'no_components': 33, 'learning_rate': 0.0011939530595721066, 'loss': 'logistic'}. Best is trial 16 with value: 0.023545121774077415.\n",
      "[I 2025-10-26 20:10:15,901] Trial 19 finished with value: 0.021279990673065186 and parameters: {'no_components': 48, 'learning_rate': 0.008017183741258373, 'loss': 'logistic'}. Best is trial 16 with value: 0.023545121774077415.\n",
      "[I 2025-10-26 20:20:53,282] Trial 20 finished with value: 0.020435569807887077 and parameters: {'no_components': 36, 'learning_rate': 0.01389246961987672, 'loss': 'logistic'}. Best is trial 16 with value: 0.023545121774077415.\n",
      "[I 2025-10-26 20:40:58,695] Trial 21 finished with value: 0.019052954390645027 and parameters: {'no_components': 70, 'learning_rate': 0.022347383658841674, 'loss': 'logistic'}. Best is trial 16 with value: 0.023545121774077415.\n",
      "[I 2025-10-26 21:06:48,409] Trial 22 finished with value: 0.017450690269470215 and parameters: {'no_components': 91, 'learning_rate': 0.005574998065920338, 'loss': 'logistic'}. Best is trial 16 with value: 0.023545121774077415.\n",
      "[I 2025-10-26 21:15:28,806] Trial 23 finished with value: 0.01754789613187313 and parameters: {'no_components': 29, 'learning_rate': 0.005244451061500796, 'loss': 'logistic'}. Best is trial 16 with value: 0.023545121774077415.\n",
      "[I 2025-10-26 21:27:46,561] Trial 24 finished with value: 0.022100165486335754 and parameters: {'no_components': 42, 'learning_rate': 0.017396626691469578, 'loss': 'logistic'}. Best is trial 16 with value: 0.023545121774077415.\n",
      "[I 2025-10-26 21:41:53,876] Trial 25 finished with value: 0.018595725297927856 and parameters: {'no_components': 49, 'learning_rate': 0.059725872141842495, 'loss': 'logistic'}. Best is trial 16 with value: 0.023545121774077415.\n",
      "[I 2025-10-26 21:57:51,762] Trial 26 finished with value: 0.017466623336076736 and parameters: {'no_components': 55, 'learning_rate': 0.0018007615935603048, 'loss': 'logistic'}. Best is trial 16 with value: 0.023545121774077415.\n",
      "[I 2025-10-26 22:18:17,153] Trial 27 finished with value: 0.02280464768409729 and parameters: {'no_components': 72, 'learning_rate': 0.025926396064164307, 'loss': 'logistic'}. Best is trial 16 with value: 0.023545121774077415.\n",
      "[I 2025-10-26 22:37:00,874] Trial 28 finished with value: 0.020207352936267853 and parameters: {'no_components': 66, 'learning_rate': 0.0128517344872144, 'loss': 'logistic'}. Best is trial 16 with value: 0.023545121774077415.\n",
      "[I 2025-10-26 22:58:01,588] Trial 29 finished with value: 0.018840331584215164 and parameters: {'no_components': 74, 'learning_rate': 0.0056220180547079, 'loss': 'logistic'}. Best is trial 16 with value: 0.023545121774077415.\n",
      "[I 2025-10-26 23:09:49,018] Trial 30 finished with value: 0.021052522584795952 and parameters: {'no_components': 41, 'learning_rate': 0.04702985273778594, 'loss': 'logistic'}. Best is trial 16 with value: 0.023545121774077415.\n",
      "[I 2025-10-26 23:35:32,029] Trial 31 finished with value: 0.02347744256258011 and parameters: {'no_components': 91, 'learning_rate': 0.02726184214215803, 'loss': 'logistic'}. Best is trial 16 with value: 0.023545121774077415.\n",
      "[I 2025-10-26 23:57:17,830] Trial 32 finished with value: 0.021523291245102882 and parameters: {'no_components': 77, 'learning_rate': 0.026337718548325933, 'loss': 'logistic'}. Best is trial 16 with value: 0.023545121774077415.\n",
      "[I 2025-10-27 00:21:20,691] Trial 33 finished with value: 0.017269207164645195 and parameters: {'no_components': 85, 'learning_rate': 0.0452820764517106, 'loss': 'logistic'}. Best is trial 16 with value: 0.023545121774077415.\n",
      "[I 2025-10-27 00:27:27,900] Trial 34 finished with value: 0.020175108686089516 and parameters: {'no_components': 20, 'learning_rate': 0.09416574641308952, 'loss': 'logistic'}. Best is trial 16 with value: 0.023545121774077415.\n",
      "[I 2025-10-27 00:43:14,823] Trial 35 finished with value: 0.022851591929793358 and parameters: {'no_components': 55, 'learning_rate': 0.013815150321968138, 'loss': 'logistic'}. Best is trial 16 with value: 0.023545121774077415.\n",
      "[I 2025-10-27 00:58:45,134] Trial 36 finished with value: 0.022098788991570473 and parameters: {'no_components': 54, 'learning_rate': 0.011449784744374324, 'loss': 'logistic'}. Best is trial 16 with value: 0.023545121774077415.\n",
      "[I 2025-10-27 01:07:39,611] Trial 37 finished with value: 0.019076615571975708 and parameters: {'no_components': 30, 'learning_rate': 0.007343508063060897, 'loss': 'logistic'}. Best is trial 16 with value: 0.023545121774077415.\n",
      "[I 2025-10-27 01:20:43,448] Trial 38 finished with value: 0.02106071077287197 and parameters: {'no_components': 45, 'learning_rate': 0.015203455706331914, 'loss': 'logistic'}. Best is trial 16 with value: 0.023545121774077415.\n",
      "[I 2025-10-27 01:35:45,767] Trial 39 finished with value: 0.01743493229150772 and parameters: {'no_components': 52, 'learning_rate': 0.003898717812343842, 'loss': 'logistic'}. Best is trial 16 with value: 0.023545121774077415.\n",
      "[I 2025-10-27 01:46:17,682] Trial 40 finished with value: 0.02239426225423813 and parameters: {'no_components': 36, 'learning_rate': 0.03476746816935369, 'loss': 'logistic'}. Best is trial 16 with value: 0.023545121774077415.\n",
      "[I 2025-10-27 02:12:32,438] Trial 41 finished with value: 0.020979121327400208 and parameters: {'no_components': 93, 'learning_rate': 0.0233368320463177, 'loss': 'logistic'}. Best is trial 16 with value: 0.023545121774077415.\n",
      "[I 2025-10-27 02:35:49,112] Trial 42 finished with value: 0.019358957186341286 and parameters: {'no_components': 82, 'learning_rate': 0.010778467005223976, 'loss': 'logistic'}. Best is trial 16 with value: 0.023545121774077415.\n",
      "[I 2025-10-27 02:52:04,826] Trial 43 finished with value: 0.021937189623713493 and parameters: {'no_components': 57, 'learning_rate': 0.0184961458429529, 'loss': 'logistic'}. Best is trial 16 with value: 0.023545121774077415.\n",
      "[I 2025-10-27 03:21:54,916] Trial 44 finished with value: 0.023653417825698853 and parameters: {'no_components': 90, 'learning_rate': 0.03352736068651356, 'loss': 'logistic'}. Best is trial 44 with value: 0.023653417825698853.\n",
      "[I 2025-10-27 03:47:39,631] Trial 45 finished with value: 0.017511781305074692 and parameters: {'no_components': 91, 'learning_rate': 0.059871342556895406, 'loss': 'logistic'}. Best is trial 44 with value: 0.023653417825698853.\n",
      "[I 2025-10-27 04:11:50,439] Trial 46 finished with value: 0.018186872825026512 and parameters: {'no_components': 86, 'learning_rate': 0.03876586810979231, 'loss': 'logistic'}. Best is trial 44 with value: 0.023653417825698853.\n",
      "[I 2025-10-27 04:39:02,062] Trial 47 finished with value: 0.017872506752610207 and parameters: {'no_components': 97, 'learning_rate': 0.006942654959244513, 'loss': 'logistic'}. Best is trial 44 with value: 0.023653417825698853.\n",
      "[I 2025-10-27 04:46:28,883] Trial 48 finished with value: 0.017921218648552895 and parameters: {'no_components': 25, 'learning_rate': 0.009498181449989034, 'loss': 'logistic'}. Best is trial 44 with value: 0.023653417825698853.\n",
      "[I 2025-10-27 04:57:46,267] Trial 49 finished with value: 0.01784825138747692 and parameters: {'no_components': 39, 'learning_rate': 0.00012275974425937194, 'loss': 'logistic'}. Best is trial 44 with value: 0.023653417825698853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      "{'no_components': 90, 'learning_rate': 0.03352736068651356, 'loss': 'logistic'}\n"
     ]
    }
   ],
   "source": [
    "# Run the optimization with Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best parameters found:\")\n",
    "print(study.best_params)\n",
    "\n",
    "# Save the best parameters to a JSON file\n",
    "os.makedirs(\"../experiments\", exist_ok=True)\n",
    "with open(\"../experiments/lightfm_best_params.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"best_params\": study.best_params,\n",
    "            \"best_precision_at_5\": study.best_value\n",
    "        },\n",
    "        f,\n",
    "        indent=4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec48de31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x1ec1c524e20>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the best parameters from the JSON file\n",
    "with open(\"../experiments/lightfm_best_params.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    best = json.load(f)\n",
    "best_params = best[\"best_params\"]\n",
    "\n",
    "# Instantiate and train the final model with the best parameters\n",
    "# and interactions from the entire training set\n",
    "final_model = LightFM(\n",
    "    no_components=best_params[\"no_components\"],\n",
    "    learning_rate=best_params[\"learning_rate\"],\n",
    "    loss=best_params[\"loss\"]\n",
    ")\n",
    "final_model.fit(\n",
    "    interactions,\n",
    "    user_features=user_features,\n",
    "    item_features=item_features,\n",
    "    epochs=20,\n",
    "    num_threads=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dbdc4770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the 50 most relevant users for each item in the test set\n",
    "\n",
    "# Load all the user IDs\n",
    "user_ids = list(user_ids)\n",
    "\n",
    "# Build the item features matrix for the test set\n",
    "test_item_features_matrix = dataset.build_item_features(test_item_features)\n",
    "\n",
    "# Generate recommendations for each test item\n",
    "# getting top 50 users for each item so its possible to compare\n",
    "# with Knowledge Graph Method results on k = 10, 20 and 50\n",
    "top_k = 50\n",
    "recommendations = {}\n",
    "\n",
    "# Mapeamento reverso do índice interno para o ID real do usuário\n",
    "user_id_map = {v: k for k, v in dataset.mapping()[0].items()}\n",
    "\n",
    "for item_id in test_item_ids:\n",
    "    # Índice interno do item de teste\n",
    "    item_internal_idx = dataset.mapping()[2][item_id]\n",
    "    # Score para todos os usuários para este item\n",
    "    scores = final_model.predict(\n",
    "        user_ids=np.arange(len(user_ids)),\n",
    "        item_ids=np.repeat(item_internal_idx, len(user_ids)),\n",
    "        user_features=user_features,\n",
    "        item_features=test_item_features_matrix\n",
    "    )\n",
    "    # Top 50 usuários (índices ordenados por score decrescente)\n",
    "    top_users_idx = np.argsort(-scores)[:top_k]\n",
    "    # IDs reais dos usuários\n",
    "    top_users = [user_ids[i] for i in top_users_idx]\n",
    "    recommendations[item_id] = top_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f7fc643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision@10 por item:\n",
      "[0.3, 0.0, 0.0, 0.1, 0.2, 0.4, 0.4, 0.1, 0.0, 0.1, 0.5, 0.6, 0.1, 0.2, 0.0, 0.3, 0.1, 0.1, 0.2, 0.0, 0.2, 0.0, 0.0, 0.2, 0.0, 0.2, 0.0, 0.0, 0.1, 0.0, 0.1, 0.0, 0.0, 0.1, 0.2, 0.0, 0.4, 0.4, 0.4, 0.0, 0.1, 0.3, 0.4, 0.1, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.0, 0.0, 0.1, 0.0, 0.0, 0.1, 0.1, 0.3, 0.0, 0.0, 0.2, 0.1, 0.0, 0.0, 0.2, 0.1, 0.1, 0.3, 0.3, 0.1, 0.1, 0.1, 0.2, 0.1, 0.1, 0.0, 0.0, 0.1, 0.0, 0.0, 0.1, 0.2, 0.0, 0.2, 0.2, 0.1, 0.2, 0.0, 0.0, 0.0, 0.1, 0.1, 0.1, 0.2, 0.1, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.0, 0.0, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.0, 0.0, 0.1, 0.0, 0.0, 0.3, 0.0, 0.0, 0.1, 0.1, 0.0, 0.0, 0.0, 0.1, 0.1, 0.0, 0.0, 0.1, 0.0, 0.1, 0.1, 0.0, 0.0, 0.1, 0.0, 0.0, 0.1, 0.0, 0.2, 0.1, 0.0, 0.1, 0.0, 0.0, 0.1, 0.1, 0.0, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.2, 0.0, 0.1, 0.0, 0.0, 0.1, 0.0, 0.0, 0.1, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.2, 0.0, 0.3, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "NDCG@10 por item:\n",
      "[np.float64(0.2520649403266671), np.float64(0.0), np.float64(0.0), np.float64(0.11004588314904008), np.float64(0.17947710508581735), np.float64(0.2816372027313761), np.float64(0.38589303732090635), np.float64(0.07839826897867533), np.float64(0.0), np.float64(0.11004588314904008), np.float64(0.40160493302575007), np.float64(0.6117748521784964), np.float64(0.06943122193677727), np.float64(0.14201905717762703), np.float64(0.0), np.float64(0.24309789328476902), np.float64(0.06362078819895171), np.float64(0.07839826897867533), np.float64(0.1884441521277154), np.float64(0.0), np.float64(0.1736666713479918), np.float64(0.0), np.float64(0.0), np.float64(0.28952298823485745), np.float64(0.0), np.float64(0.28371255449703187), np.float64(0.0), np.float64(0.0), np.float64(0.06362078819895171), np.float64(0.0), np.float64(0.11004588314904008), np.float64(0.0), np.float64(0.0), np.float64(0.06362078819895171), np.float64(0.20248323207250624), np.float64(0.0), np.float64(0.4631896595828492), np.float64(0.4721567066247473), np.float64(0.4721567066247473), np.float64(0.0), np.float64(0.11004588314904008), np.float64(0.3125291152215463), np.float64(0.4936790360674166), np.float64(0.08514311764162098), np.float64(0.0), np.float64(0.1487639058405727), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.11004588314904008), np.float64(0.06362078819895171), np.float64(0.0), np.float64(0.0), np.float64(0.22009176629808017), np.float64(0.0), np.float64(0.0), np.float64(0.11004588314904008), np.float64(0.06362078819895171), np.float64(0.2520649403266671), np.float64(0.0), np.float64(0.0), np.float64(0.1884441521277154), np.float64(0.11004588314904008), np.float64(0.0), np.float64(0.0), np.float64(0.1736666713479918), np.float64(0.06362078819895171), np.float64(0.11004588314904008), np.float64(0.25880978898961277), np.float64(0.2520649403266671), np.float64(0.11004588314904008), np.float64(0.06362078819895171), np.float64(0.13886244387355454), np.float64(0.1635413866202963), np.float64(0.06362078819895171), np.float64(0.11004588314904008), np.float64(0.0), np.float64(0.0), np.float64(0.07839826897867533), np.float64(0.0), np.float64(0.0), np.float64(0.11004588314904008), np.float64(0.1884441521277154), np.float64(0.0), np.float64(0.19518900079066107), np.float64(0.1635413866202963), np.float64(0.11004588314904008), np.float64(0.28371255449703187), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.11004588314904008), np.float64(0.06362078819895171), np.float64(0.11004588314904008), np.float64(0.1736666713479918), np.float64(0.07336392209936005), np.float64(0.1884441521277154), np.float64(0.07839826897867533), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.22009176629808017), np.float64(0.11004588314904008), np.float64(0.0), np.float64(0.0), np.float64(0.06362078819895171), np.float64(0.13886244387355454), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.07839826897867533), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.07839826897867533), np.float64(0.07839826897867533), np.float64(0.0), np.float64(0.0), np.float64(0.06362078819895171), np.float64(0.0), np.float64(0.0), np.float64(0.22716217481924803), np.float64(0.0), np.float64(0.0), np.float64(0.06362078819895171), np.float64(0.11004588314904008), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.07839826897867533), np.float64(0.11004588314904008), np.float64(0.0), np.float64(0.0), np.float64(0.11004588314904008), np.float64(0.0), np.float64(0.11004588314904008), np.float64(0.22009176629808017), np.float64(0.0), np.float64(0.0), np.float64(0.11004588314904008), np.float64(0.0), np.float64(0.0), np.float64(0.22009176629808017), np.float64(0.0), np.float64(0.14201905717762703), np.float64(0.11004588314904008), np.float64(0.0), np.float64(0.11004588314904008), np.float64(0.0), np.float64(0.0), np.float64(0.11004588314904008), np.float64(0.11004588314904008), np.float64(0.0), np.float64(0.22009176629808017), np.float64(0.22009176629808017), np.float64(0.11004588314904008), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.06362078819895171), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.20248323207250624), np.float64(0.0), np.float64(0.22009176629808017), np.float64(0.0), np.float64(0.0), np.float64(0.07839826897867533), np.float64(0.0), np.float64(0.0), np.float64(0.22009176629808017), np.float64(0.0), np.float64(0.11004588314904008), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.07839826897867533), np.float64(0.0), np.float64(0.1736666713479918), np.float64(0.0), np.float64(0.2520649403266671), np.float64(0.06362078819895171), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.11004588314904008), np.float64(0.06362078819895171), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.11004588314904008), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.11004588314904008), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.11004588314904008), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)]\n",
      "\n",
      "Precision@20 por item:\n",
      "[0.25, 0.0, 0.0, 0.05, 0.1, 0.45, 0.45, 0.05, 0.05, 0.05, 0.6, 0.65, 0.05, 0.1, 0.0, 0.2, 0.2, 0.05, 0.2, 0.0, 0.2, 0.05, 0.0, 0.15, 0.05, 0.1, 0.0, 0.0, 0.05, 0.0, 0.05, 0.0, 0.05, 0.1, 0.2, 0.0, 0.25, 0.35, 0.2, 0.0, 0.05, 0.25, 0.3, 0.05, 0.05, 0.15, 0.0, 0.15, 0.0, 0.1, 0.2, 0.05, 0.0, 0.0, 0.05, 0.05, 0.1, 0.05, 0.05, 0.35, 0.05, 0.0, 0.2, 0.15, 0.0, 0.05, 0.1, 0.1, 0.05, 0.4, 0.15, 0.2, 0.2, 0.05, 0.15, 0.1, 0.05, 0.0, 0.0, 0.05, 0.0, 0.0, 0.1, 0.2, 0.0, 0.25, 0.15, 0.15, 0.1, 0.0, 0.0, 0.0, 0.05, 0.05, 0.05, 0.1, 0.1, 0.1, 0.15, 0.0, 0.05, 0.0, 0.05, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 0.1, 0.05, 0.0, 0.0, 0.15, 0.1, 0.0, 0.0, 0.0, 0.0, 0.05, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.05, 0.1, 0.05, 0.05, 0.0, 0.1, 0.0, 0.0, 0.15, 0.0, 0.0, 0.1, 0.1, 0.05, 0.05, 0.0, 0.1, 0.1, 0.0, 0.05, 0.05, 0.0, 0.05, 0.2, 0.0, 0.0, 0.05, 0.1, 0.0, 0.1, 0.05, 0.1, 0.05, 0.05, 0.05, 0.0, 0.0, 0.1, 0.05, 0.0, 0.05, 0.05, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05, 0.0, 0.05, 0.0, 0.05, 0.05, 0.2, 0.0, 0.05, 0.05, 0.05, 0.05, 0.0, 0.0, 0.05, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05, 0.0, 0.1, 0.0, 0.15, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05, 0.0, 0.0, 0.05, 0.05, 0.0, 0.0, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "NDCG@20 por item:\n",
      "[np.float64(0.239602299600595), np.float64(0.0), np.float64(0.0), np.float64(0.07102001981682865), np.float64(0.11582866341850039), np.float64(0.35971859439038734), np.float64(0.4214651235585331), np.float64(0.05059568297461706), np.float64(0.0383846381653829), np.float64(0.07102001981682865), np.float64(0.5075824230732017), np.float64(0.6441483764633005), np.float64(0.044808643601671735), np.float64(0.09165446236150611), np.float64(0.0), np.float64(0.19650850986120502), np.float64(0.1446466792681688), np.float64(0.05059568297461706), np.float64(0.19126074430621018), np.float64(0.0), np.float64(0.18403815740785315), np.float64(0.032864970567577), np.float64(0.0), np.float64(0.2241554336017737), np.float64(0.0334374913847135), np.float64(0.18309881902054637), np.float64(0.0), np.float64(0.0), np.float64(0.04105877938688906), np.float64(0.0), np.float64(0.07102001981682865), np.float64(0.0), np.float64(0.039621067055815605), np.float64(0.0783655297533337), np.float64(0.20192567532319242), np.float64(0.0), np.float64(0.3385485494948623), np.float64(0.409258473884113), np.float64(0.30471452181199205), np.float64(0.0), np.float64(0.07102001981682865), np.float64(0.266899348122958), np.float64(0.3945816855414434), np.float64(0.05494858807198588), np.float64(0.032864970567577), np.float64(0.13562843451469056), np.float64(0.0), np.float64(0.10439521421363303), np.float64(0.0), np.float64(0.07017172093402163), np.float64(0.17097345423159405), np.float64(0.04105877938688906), np.float64(0.0), np.float64(0.0), np.float64(0.1420400396336573), np.float64(0.032864970567577), np.float64(0.07597735504435443), np.float64(0.07102001981682865), np.float64(0.04105877938688906), np.float64(0.3011326686479503), np.float64(0.039621067055815605), np.float64(0.0), np.float64(0.19367262585675893), np.float64(0.1406650613315931), np.float64(0.0), np.float64(0.03730675036644464), np.float64(0.11207879920371772), np.float64(0.0783655297533337), np.float64(0.07102001981682865), np.float64(0.33703786299874106), np.float64(0.16267448217833477), np.float64(0.17462923213556378), np.float64(0.14598067301977927), np.float64(0.08961728720334347), np.float64(0.13788256219492276), np.float64(0.07392374995446606), np.float64(0.07102001981682865), np.float64(0.0), np.float64(0.0), np.float64(0.05059568297461706), np.float64(0.0), np.float64(0.0), np.float64(0.11064108687264426), np.float64(0.18739148532447902), np.float64(0.0), np.float64(0.23428425408148879), np.float64(0.13788256219492276), np.float64(0.14297937802096408), np.float64(0.18309881902054637), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.07102001981682865), np.float64(0.04105877938688906), np.float64(0.07102001981682865), np.float64(0.11207879920371772), np.float64(0.07968497102620559), np.float64(0.1216157027914457), np.float64(0.12308172059800965), np.float64(0.0), np.float64(0.03233829114831982), np.float64(0.0), np.float64(0.032864970567577), np.float64(0.0), np.float64(0.03730675036644464), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.17437833078197715), np.float64(0.07102001981682865), np.float64(0.0), np.float64(0.0), np.float64(0.10626204110278588), np.float64(0.12436745990221204), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.032864970567577), np.float64(0.032864970567577), np.float64(0.08346065354219406), np.float64(0.0), np.float64(0.032864970567577), np.float64(0.06520326171589681), np.float64(0.0), np.float64(0.036356287988538835), np.float64(0.08346065354219406), np.float64(0.05059568297461706), np.float64(0.032864970567577), np.float64(0.0), np.float64(0.07339707053520887), np.float64(0.0), np.float64(0.0), np.float64(0.146603050433492), np.float64(0.0), np.float64(0.0), np.float64(0.08067984644270466), np.float64(0.10388499038440566), np.float64(0.032864970567577), np.float64(0.03406297225598251), np.float64(0.0), np.float64(0.08346065354219406), np.float64(0.10388499038440566), np.float64(0.0), np.float64(0.03233829114831982), np.float64(0.07102001981682865), np.float64(0.0), np.float64(0.07102001981682865), np.float64(0.24562793951493703), np.float64(0.0), np.float64(0.0), np.float64(0.07102001981682865), np.float64(0.06979377937325233), np.float64(0.0), np.float64(0.17839632762219612), np.float64(0.032864970567577), np.float64(0.09165446236150611), np.float64(0.07102001981682865), np.float64(0.039621067055815605), np.float64(0.07102001981682865), np.float64(0.0), np.float64(0.0), np.float64(0.10577019251569722), np.float64(0.07102001981682865), np.float64(0.0), np.float64(0.1420400396336573), np.float64(0.1420400396336573), np.float64(0.07102001981682865), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.03730675036644464), np.float64(0.0), np.float64(0.04105877938688906), np.float64(0.0), np.float64(0.032864970567577), np.float64(0.036356287988538835), np.float64(0.20204578921265967), np.float64(0.0), np.float64(0.1420400396336573), np.float64(0.032864970567577), np.float64(0.032864970567577), np.float64(0.05059568297461706), np.float64(0.0), np.float64(0.0), np.float64(0.1420400396336573), np.float64(0.0), np.float64(0.07102001981682865), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.05059568297461706), np.float64(0.0), np.float64(0.11207879920371772), np.float64(0.0), np.float64(0.16267448217833477), np.float64(0.04105877938688906), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.03233829114831982), np.float64(0.0), np.float64(0.0), np.float64(0.07102001981682865), np.float64(0.04105877938688906), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.032864970567577), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.07102001981682865), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.039621067055815605), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.07102001981682865), np.float64(0.0), np.float64(0.036356287988538835), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.07102001981682865), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)]\n",
      "\n",
      "Precision@50 por item:\n",
      "[0.34, 0.1, 0.06, 0.38, 0.28, 0.56, 0.48, 0.12, 0.2, 0.1, 0.72, 0.7, 0.1, 0.14, 0.02, 0.46, 0.28, 0.22, 0.44, 0.02, 0.4, 0.04, 0.04, 0.24, 0.16, 0.16, 0.08, 0.0, 0.06, 0.02, 0.18, 0.02, 0.16, 0.08, 0.2, 0.04, 0.36, 0.34, 0.2, 0.12, 0.1, 0.22, 0.38, 0.06, 0.02, 0.22, 0.06, 0.16, 0.0, 0.08, 0.26, 0.06, 0.02, 0.14, 0.14, 0.06, 0.2, 0.1, 0.14, 0.46, 0.06, 0.1, 0.2, 0.2, 0.1, 0.1, 0.24, 0.18, 0.08, 0.34, 0.12, 0.26, 0.24, 0.1, 0.18, 0.1, 0.02, 0.02, 0.04, 0.16, 0.06, 0.02, 0.22, 0.34, 0.04, 0.42, 0.38, 0.18, 0.08, 0.06, 0.02, 0.0, 0.06, 0.04, 0.18, 0.26, 0.16, 0.16, 0.16, 0.12, 0.2, 0.14, 0.12, 0.06, 0.14, 0.12, 0.06, 0.16, 0.1, 0.1, 0.14, 0.2, 0.02, 0.2, 0.08, 0.04, 0.06, 0.02, 0.1, 0.04, 0.02, 0.22, 0.06, 0.06, 0.28, 0.02, 0.18, 0.06, 0.18, 0.08, 0.0, 0.14, 0.02, 0.06, 0.24, 0.02, 0.0, 0.14, 0.08, 0.02, 0.08, 0.08, 0.06, 0.08, 0.0, 0.04, 0.18, 0.02, 0.04, 0.24, 0.04, 0.0, 0.14, 0.08, 0.0, 0.18, 0.08, 0.12, 0.04, 0.12, 0.22, 0.06, 0.02, 0.1, 0.04, 0.02, 0.06, 0.04, 0.08, 0.06, 0.08, 0.02, 0.0, 0.04, 0.04, 0.0, 0.04, 0.02, 0.0, 0.04, 0.0, 0.04, 0.02, 0.12, 0.02, 0.1, 0.06, 0.28, 0.0, 0.04, 0.08, 0.04, 0.04, 0.0, 0.06, 0.04, 0.02, 0.06, 0.08, 0.0, 0.06, 0.02, 0.04, 0.04, 0.14, 0.02, 0.06, 0.02, 0.12, 0.06, 0.06, 0.1, 0.02, 0.02, 0.08, 0.06, 0.08, 0.0, 0.02, 0.04, 0.04, 0.02, 0.12, 0.12, 0.02, 0.06, 0.08, 0.06, 0.04, 0.0, 0.02, 0.06, 0.08, 0.04, 0.02, 0.04, 0.04, 0.04, 0.04, 0.0, 0.04, 0.02, 0.02, 0.02, 0.04, 0.02, 0.02, 0.02, 0.02, 0.02, 0.04, 0.06, 0.06, 0.02, 0.08, 0.0, 0.04, 0.04, 0.0, 0.02, 0.0, 0.0, 0.0, 0.0, 0.02, 0.02, 0.02, 0.0, 0.04, 0.0, 0.02, 0.0, 0.0, 0.04, 0.0, 0.06, 0.08, 0.02, 0.02, 0.0, 0.04, 0.02, 0.0, 0.04, 0.0, 0.0, 0.02, 0.04, 0.0, 0.0, 0.04, 0.04, 0.02, 0.0, 0.04, 0.0, 0.0]\n",
      "NDCG@50 por item:\n",
      "[np.float64(0.31410921929396823), np.float64(0.07481407173145936), np.float64(0.046839063764931556), np.float64(0.3107692110939496), np.float64(0.2416303734486964), np.float64(0.4800570344284823), np.float64(0.4596241027876512), np.float64(0.0991070961288236), np.float64(0.1503048437912597), np.float64(0.09587736486626146), np.float64(0.6421353404638865), np.float64(0.6795333497089825), np.float64(0.08206527016939358), np.float64(0.1278126066383606), np.float64(0.014201662815287893), np.float64(0.3988251108580446), np.float64(0.22485983378583077), np.float64(0.17799449258298852), np.float64(0.3793625333759849), np.float64(0.01550660140220166), np.float64(0.33958068335095715), np.float64(0.03317946303311285), np.float64(0.02770518194389191), np.float64(0.2579000121147388), np.float64(0.12585594473321518), np.float64(0.19273886479236402), np.float64(0.06017151548560776), np.float64(0.0), np.float64(0.0556283071408891), np.float64(0.016305960335703182), np.float64(0.15553756114623343), np.float64(0.014036776925438005), np.float64(0.127274695642805), np.float64(0.07441067210926403), np.float64(0.20216399144032918), np.float64(0.02855173074059695), np.float64(0.3789396058981351), np.float64(0.37640227364116596), np.float64(0.2540619677999679), np.float64(0.08799639823509448), np.float64(0.10134486869543533), np.float64(0.23815619057743112), np.float64(0.40986735088258647), np.float64(0.059437158212093284), np.float64(0.017939448623110178), np.float64(0.1938319628008446), np.float64(0.048693742212315226), np.float64(0.1344917419814952), np.float64(0.0), np.float64(0.06988301126513896), np.float64(0.2295090333256652), np.float64(0.05233073048417319), np.float64(0.014669272800906774), np.float64(0.10527932365414522), np.float64(0.16668727534706593), np.float64(0.048187839920028064), np.float64(0.16064407829952068), np.float64(0.09846662507906732), np.float64(0.11105740425106388), np.float64(0.4099395972136467), np.float64(0.051991514677584914), np.float64(0.07367710209696826), np.float64(0.19384066565585586), np.float64(0.18354586214969562), np.float64(0.07310107294662242), np.float64(0.08082431445043244), np.float64(0.21282301539428622), np.float64(0.1526903763522704), np.float64(0.08225501070758744), np.float64(0.32519503353662577), np.float64(0.13356454166540557), np.float64(0.23082903045926143), np.float64(0.204787201471904), np.float64(0.10918149417725706), np.float64(0.16717361770554745), np.float64(0.0866236677854027), np.float64(0.038766503505504146), np.float64(0.014883136784092805), np.float64(0.028706049726344777), np.float64(0.13049028332248466), np.float64(0.046656514656946084), np.float64(0.016305960335703182), np.float64(0.1922029379647859), np.float64(0.3015643688777075), np.float64(0.0332162419353484), np.float64(0.36339000840469343), np.float64(0.31352229862265335), np.float64(0.16735021406369222), np.float64(0.12870526231832877), np.float64(0.044551241130853604), np.float64(0.014201662815287893), np.float64(0.0), np.float64(0.06995560062530012), np.float64(0.036080470223994604), np.float64(0.15876237599966442), np.float64(0.22987390606439567), np.float64(0.1396807424010405), np.float64(0.1594762806936938), np.float64(0.14320493180300362), np.float64(0.08564297260054678), np.float64(0.14857979717844116), np.float64(0.10294163800778315), np.float64(0.09018968080035861), np.float64(0.04528778225990662), np.float64(0.1121783984295239), np.float64(0.08655415815730666), np.float64(0.046408622657889094), np.float64(0.11848772088956205), np.float64(0.07279386763735372), np.float64(0.1375454149696828), np.float64(0.1288296762529559), np.float64(0.14998918658348034), np.float64(0.013668405018453907), np.float64(0.16255342114766108), np.float64(0.0999124140154044), np.float64(0.030433418667098096), np.float64(0.04431587660678827), np.float64(0.014471722709210601), np.float64(0.07687101950554591), np.float64(0.031607853641564085), np.float64(0.017939448623110178), np.float64(0.17752535383335247), np.float64(0.04282930572806914), np.float64(0.046381877637206644), np.float64(0.2113756708125586), np.float64(0.014669272800906774), np.float64(0.13669073343859006), np.float64(0.0601258564510805), np.float64(0.14559932270561302), np.float64(0.061051150438113426), np.float64(0.0), np.float64(0.11365185920195313), np.float64(0.014471722709210601), np.float64(0.04422537182032297), np.float64(0.22212326229534995), np.float64(0.01550660140220166), np.float64(0.0), np.float64(0.11825983552045423), np.float64(0.08778593645996005), np.float64(0.017939448623110178), np.float64(0.0657956236427381), np.float64(0.06116742123120825), np.float64(0.0601258564510805), np.float64(0.08674950683312496), np.float64(0.0), np.float64(0.03232123178932563), np.float64(0.1641609285932247), np.float64(0.01456859349255249), np.float64(0.053540527501146705), np.float64(0.2533656682005159), np.float64(0.03073394789999127), np.float64(0.0), np.float64(0.12906229868021335), np.float64(0.06817235115736682), np.float64(0.0), np.float64(0.2023307846888077), np.float64(0.06161547702962236), np.float64(0.1115833949155493), np.float64(0.05413663620656854), np.float64(0.09663932805399049), np.float64(0.18834375207886328), np.float64(0.0440759387058046), np.float64(0.016910281599645218), np.float64(0.10190848493022282), np.float64(0.053540527501146705), np.float64(0.01550660140220166), np.float64(0.10697630380755761), np.float64(0.0924161437951011), np.float64(0.08130780478073009), np.float64(0.047461492889990735), np.float64(0.05979922020731483), np.float64(0.014201662815287893), np.float64(0.0), np.float64(0.031079984331345737), np.float64(0.03007519489475415), np.float64(0.0), np.float64(0.0290385377195183), np.float64(0.014036776925438005), np.float64(0.0), np.float64(0.029708264217489552), np.float64(0.0), np.float64(0.0348357309506874), np.float64(0.01550660140220166), np.float64(0.10094772653771883), np.float64(0.014378420432648437), np.float64(0.07775079243651188), np.float64(0.04846592648500351), np.float64(0.26372582063603733), np.float64(0.0), np.float64(0.09210160050356078), np.float64(0.06210103363269575), np.float64(0.03358941526824575), np.float64(0.04431363863370848), np.float64(0.0), np.float64(0.04484115901664007), np.float64(0.09210160050356078), np.float64(0.016910281599645218), np.float64(0.06820980030205347), np.float64(0.05916346739585856), np.float64(0.0), np.float64(0.045306919583551486), np.float64(0.014378420432648437), np.float64(0.031198748992214392), np.float64(0.028415197358086442), np.float64(0.11967766336568363), np.float64(0.01550660140220166), np.float64(0.07856486670628143), np.float64(0.014288467392569172), np.float64(0.13529381661393702), np.float64(0.05099499636889216), np.float64(0.045550156106712286), np.float64(0.07692403234374591), np.float64(0.016305960335703182), np.float64(0.01550660140220166), np.float64(0.05862074626745544), np.float64(0.046101029130474015), np.float64(0.06438378894284964), np.float64(0.0), np.float64(0.01550660140220166), np.float64(0.031389553357226305), np.float64(0.032892899397438245), np.float64(0.01456859349255249), np.float64(0.11231798161412966), np.float64(0.0956376312602626), np.float64(0.013737594368807445), np.float64(0.04314401515643142), np.float64(0.05932526512649615), np.float64(0.0479830033276208), np.float64(0.0290847995993807), np.float64(0.0), np.float64(0.01550660140220166), np.float64(0.04318932464545274), np.float64(0.0825808437029098), np.float64(0.03168430559528777), np.float64(0.013808907167708913), np.float64(0.03007519489475415), np.float64(0.031812561737904844), np.float64(0.03210680315058016), np.float64(0.028415197358086442), np.float64(0.0), np.float64(0.030947058525083223), np.float64(0.017386297995236586), np.float64(0.014378420432648437), np.float64(0.021627285360840357), np.float64(0.030876734103266055), np.float64(0.014669272800906774), np.float64(0.014378420432648437), np.float64(0.015649966645135568), np.float64(0.017386297995236586), np.float64(0.01550660140220166), np.float64(0.032892899397438245), np.float64(0.06743988903000264), np.float64(0.04460668069035787), np.float64(0.01984519533210326), np.float64(0.0614000436584657), np.float64(0.0), np.float64(0.03369225833093977), np.float64(0.03087455382825567), np.float64(0.0), np.float64(0.01580084281487698), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.014036776925438005), np.float64(0.014288467392569172), np.float64(0.014288467392569172), np.float64(0.0), np.float64(0.03007519489475415), np.float64(0.0), np.float64(0.01550660140220166), np.float64(0.0), np.float64(0.0), np.float64(0.029458873812844483), np.float64(0.0), np.float64(0.04625723361143126), np.float64(0.058444256044397645), np.float64(0.014669272800906774), np.float64(0.014117822463755503), np.float64(0.0), np.float64(0.05507246384120733), np.float64(0.014774023995642555), np.float64(0.0), np.float64(0.03192884007492186), np.float64(0.0), np.float64(0.0), np.float64(0.01550660140220166), np.float64(0.03136509709919742), np.float64(0.0), np.float64(0.0), np.float64(0.02953242458482574), np.float64(0.02965716077973536), np.float64(0.014471722709210601), np.float64(0.0), np.float64(0.03238322870300857), np.float64(0.0), np.float64(0.0)]\n"
     ]
    }
   ],
   "source": [
    "# Calculate precision@k and ndcg@k for k = 10, 20, 50\n",
    "def precision_at_k(recommended, relevant, k):\n",
    "    recommended_k = recommended[:k]\n",
    "    relevant_set = set(relevant)\n",
    "    hits = sum([1 for user in recommended_k if user in relevant_set])\n",
    "    return hits / k\n",
    "\n",
    "def dcg_at_k(recommended, relevant, k):\n",
    "    recommended_k = recommended[:k]\n",
    "    relevant_set = set(relevant)\n",
    "    return sum([1 / np.log2(idx + 2) if user in relevant_set else 0\n",
    "                for idx, user in enumerate(recommended_k)])\n",
    "\n",
    "def ndcg_at_k(recommended, relevant, k):\n",
    "    dcg = dcg_at_k(recommended, relevant, k)\n",
    "    ideal_dcg = sum([1 / np.log2(idx + 2) for idx in range(min(len(relevant), k))])\n",
    "    return dcg / ideal_dcg if ideal_dcg > 0 else 0.0\n",
    "\n",
    "ks = [10, 20, 50]\n",
    "precision_scores = {k: [] for k in ks}\n",
    "ndcg_scores = {k: [] for k in ks}\n",
    "\n",
    "# Crie um dicionário: item_id -> lista de usuários relevantes (do test_interactions_df)\n",
    "test_relevant = (\n",
    "    test_interactions_df.groupby('item_id')['user_id']\n",
    "    .apply(list)\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "for item_id, recommended_users in recommendations.items():\n",
    "    # Converta ambos para string para garantir a comparação correta\n",
    "    relevant_users = [str(u) for u in test_relevant.get(int(item_id), [])]\n",
    "    recommended_users = [str(u) for u in recommended_users]\n",
    "    for k in ks:\n",
    "        prec = precision_at_k(recommended_users, relevant_users, k)\n",
    "        ndcg = ndcg_at_k(recommended_users, relevant_users, k)\n",
    "        precision_scores[k].append(prec)\n",
    "        ndcg_scores[k].append(ndcg)\n",
    "\n",
    "for k in ks:\n",
    "    print(f\"\\nPrecision@{k} por item:\")\n",
    "    print(precision_scores[k])  # Lista com 30 valores\n",
    "\n",
    "    print(f\"NDCG@{k} por item:\")\n",
    "    print(ndcg_scores[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa913dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10: 0.0562\n",
      "NDCG@10: 0.0565\n",
      "Precision@20: 0.0522\n",
      "NDCG@20: 0.0533\n",
      "Precision@50: 0.0950\n",
      "NDCG@50: 0.0849\n"
     ]
    }
   ],
   "source": [
    "# Média para cada k\n",
    "for k in ks:\n",
    "    print(f\"Precision@{k}: {np.mean(precision_scores[k]):.4f}\")\n",
    "    print(f\"NDCG@{k}: {np.mean(ndcg_scores[k]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e56e103",
   "metadata": {},
   "source": [
    "Média no dataset Movielens 100k\n",
    "Precision@10: 0.1667\n",
    "NDCG@10: 0.1859\n",
    "Precision@20: 0.1733\n",
    "NDCG@20: 0.1819\n",
    "Precision@50: 0.2173\n",
    "NDCG@50: 0.2108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc306361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar listas completas de métricas por item\n",
    "results = {\n",
    "    **{f\"precision@{k}\": precision_scores[k] for k in ks},\n",
    "    **{f\"ndcg@{k}\": ndcg_scores[k] for k in ks}\n",
    "}\n",
    "\n",
    "with open(\"../experiments/lightfm_final_metrics.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kgenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
