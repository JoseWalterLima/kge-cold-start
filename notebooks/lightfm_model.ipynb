{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b39d41a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import json\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "import optuna\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from lightfm.evaluation import precision_at_k\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Default path to data files\n",
    "PATH = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccec6192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating\n",
       "0      196      242       3\n",
       "1      186      302       3\n",
       "2       22      377       1\n",
       "3      244       51       2\n",
       "4      166      346       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load user-item interaction data\n",
    "interaction_data = pd.read_csv(\n",
    "    PATH + 'ml-100k/u.data',\n",
    "    sep='\\t',\n",
    "    encoding=\"latin1\",\n",
    "    names=['user_id', 'item_id', 'rating', 'timestamp']\n",
    "    )[['user_id', 'item_id', 'rating']]\n",
    "display(interaction_data.shape)\n",
    "interaction_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db06c50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1', ['age:24', 'gender:M', 'occupation:technician', 'zipcode:85'])\n",
      "('2', ['age:53', 'gender:F', 'occupation:other', 'zipcode:94'])\n",
      "('3', ['age:23', 'gender:M', 'occupation:writer', 'zipcode:32'])\n",
      "('4', ['age:24', 'gender:M', 'occupation:technician', 'zipcode:43'])\n",
      "('5', ['age:33', 'gender:F', 'occupation:other', 'zipcode:15'])\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a defaultdict to hold user features\n",
    "user_data = defaultdict(dict)\n",
    "\n",
    "# Read data and build user features dictionary\n",
    "def load_feature(file_path, feature_name):\n",
    "    with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            userId = row['userId']\n",
    "            value = row[feature_name]\n",
    "            user_data[userId][feature_name] = value\n",
    "\n",
    "# Load each feature file\n",
    "load_feature(PATH + 'ageRel.csv', 'age')\n",
    "load_feature(PATH + 'genderRel.csv', 'gender')\n",
    "load_feature(PATH + 'occupationRel.csv', 'occupation')\n",
    "load_feature(PATH + 'residesRel.csv', 'zipcode')\n",
    "\n",
    "# Build user features list\n",
    "user_features_raw = [\n",
    "    (userId, [f'age:{data[\"age\"]}', f'gender:{data[\"gender\"]}',\n",
    "              f'occupation:{data[\"occupation\"]}', f'zipcode:{data[\"zipcode\"]}'])\n",
    "    for userId, data in user_data.items()\n",
    "]\n",
    "\n",
    "# Display first 5 user features\n",
    "for item in user_features_raw[:5]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20b9aca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2', ['releaseDate:Jan-1995', 'genre:Action', 'genre:Adventure', 'genre:Thriller'])\n",
      "('4', ['releaseDate:Jan-1995', 'genre:Action', 'genre:Comedy', 'genre:Drama'])\n",
      "('17', ['releaseDate:Feb-1996', 'genre:Action', 'genre:Comedy', 'genre:Crime', 'genre:Horror', 'genre:Thriller'])\n",
      "('21', ['releaseDate:Feb-1996', 'genre:Action', 'genre:Adventure', 'genre:Comedy', 'genre:Musical', 'genre:Thriller'])\n",
      "('22', ['releaseDate:Feb-1996', 'genre:Action', 'genre:Drama', 'genre:War'])\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a defaultdict to hold item features\n",
    "item_data = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "# Read data and build item features dictionary\n",
    "# Modified version to handle multiple genres\n",
    "def load_feature(file_path, feature_name):\n",
    "    with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            itemId = row['movieId']\n",
    "            value = row[feature_name]\n",
    "            if feature_name == 'genreDesc':\n",
    "                item_data[itemId]['genre'].append(value)\n",
    "            else:\n",
    "                item_data[itemId][feature_name] = value\n",
    "\n",
    "# Load each feature file\n",
    "load_feature(PATH + 'releaseRel.csv', 'releaseDate')\n",
    "load_feature(PATH + 'genreRel.csv', 'genreDesc')\n",
    "\n",
    "# Build item features list\n",
    "item_features_raw = [\n",
    "    (\n",
    "        itemId,\n",
    "        [f'releaseDate:{data[\"releaseDate\"]}'] +\n",
    "        [f'genre:{genre}' for genre in data['genre']]\n",
    "    )\n",
    "    for itemId, data in item_data.items()\n",
    "]\n",
    "\n",
    "# Display first 5 item features\n",
    "for item in item_features_raw[:5]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6969351e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items on test set: 30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['159', '458', '679', '128', '658']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load test item IDs from the json file saved\n",
    "# previously from Knowledge Graph Method\n",
    "with open('../experiments/test_ids.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "# Extract test item IDs as integers\n",
    "test_item_ids = [item['movieId'] for item in data]\n",
    "print(f\"items on test set: {len(test_item_ids)}\")\n",
    "display(test_item_ids[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42ddacae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets for later evaluation\n",
    "# with LightFM the same way as done in Knowledge Graph Method\n",
    "\n",
    "# Interaction data for training (excluding test items)\n",
    "# Remover todas as interações dos itens de teste permite\n",
    "# simular o cenário de recomendação de novos itens\n",
    "train_interactions_df = interaction_data[\n",
    "    ~interaction_data['item_id'].astype(str).isin(test_item_ids)]\n",
    "\n",
    "# Interaction data for testing (only test items)\n",
    "# Usado na etapa de avaliação como ground truth\n",
    "test_interactions_df = interaction_data[\n",
    "    interaction_data['item_id'].astype(str).isin(test_item_ids)]\n",
    "\n",
    "# Item side features for testing (only testing items)\n",
    "test_item_features = [item for item in item_features_raw if item[0] in test_item_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ce4cca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build lightfm Dataset\n",
    "dataset = Dataset()\n",
    "\n",
    "# All unique user and item ids because LightFM needs all ids\n",
    "# even if some items are only in the test set\n",
    "user_ids = interaction_data['user_id'].astype(str).unique()\n",
    "# Os itens em cold start precisam estar no dataset\n",
    "item_ids = interaction_data['item_id'].astype(str).unique()\n",
    "\n",
    "# Unique features from user and item features\n",
    "user_feature_set = set(f for _, feats in user_features_raw for f in feats)\n",
    "item_feature_set = set(f for _, feats in item_features_raw for f in feats)\n",
    "\n",
    "# Partial fit\n",
    "dataset.fit(\n",
    "    users=user_ids,\n",
    "    items=item_ids,\n",
    "    user_features=user_feature_set,\n",
    "    item_features=item_feature_set\n",
    ")\n",
    "\n",
    "# Build training matrices considering only training interactions\n",
    "# so its possible to simulate cold-start for items in the test set\n",
    "(interactions, weights) = dataset.build_interactions(\n",
    "    [(str(row['user_id']), str(row['item_id']), row['rating']) for _, row in train_interactions_df.iterrows()]\n",
    ")\n",
    "\n",
    "user_features = dataset.build_user_features(user_features_raw)\n",
    "item_features = dataset.build_item_features(item_features_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ed60c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement hiperparameter tuning using Optuna\n",
    "# to find the best parameters for LightFM model\n",
    "\n",
    "# Define the objective function for optimization\n",
    "def objective(trial):\n",
    "    # Hiperparâmetros a otimizar\n",
    "    no_components = trial.suggest_int('no_components', 20, 100)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n",
    "    loss = trial.suggest_categorical('loss', ['logistic'])\n",
    "\n",
    "    # Validação cruzada: média de N splits\n",
    "    n_splits = 3\n",
    "    scores = []\n",
    "\n",
    "    for _ in range(n_splits):\n",
    "        # Split data into train and validation sets\n",
    "        train, valid = random_train_test_split(\n",
    "            interactions, test_percentage=0.2)\n",
    "        \n",
    "        # Instantiate and train the model\n",
    "        model = LightFM(\n",
    "            no_components=no_components,\n",
    "            learning_rate=learning_rate,\n",
    "            loss=loss\n",
    "        )\n",
    "\n",
    "        model.fit(\n",
    "            train,\n",
    "            user_features=user_features,\n",
    "            item_features=item_features,\n",
    "            epochs=20,\n",
    "            num_threads=4\n",
    "        )\n",
    "\n",
    "        # Evaluate the model using precision@k\n",
    "        score = precision_at_k(\n",
    "            model,\n",
    "            valid,\n",
    "            k=5,\n",
    "            user_features=user_features,\n",
    "            item_features=item_features\n",
    "        ).mean()\n",
    "        scores.append(score)\n",
    "        \n",
    "    return sum(scores) / len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1e7ccd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 09:55:17,832] A new study created in memory with name: no-name-557d4d65-4a9e-4809-b03c-a6f24e5ccfac\n",
      "[I 2025-10-21 09:58:07,796] Trial 0 finished with value: 0.02654140256345272 and parameters: {'no_components': 56, 'learning_rate': 0.00021276288037436626, 'loss': 'logistic'}. Best is trial 0 with value: 0.02654140256345272.\n",
      "[I 2025-10-21 10:00:17,255] Trial 1 finished with value: 0.0217268243432045 and parameters: {'no_components': 42, 'learning_rate': 0.0014694546937152652, 'loss': 'logistic'}. Best is trial 0 with value: 0.02654140256345272.\n",
      "[I 2025-10-21 10:01:24,572] Trial 2 finished with value: 0.015511673875153065 and parameters: {'no_components': 21, 'learning_rate': 0.055534227485426996, 'loss': 'logistic'}. Best is trial 0 with value: 0.02654140256345272.\n",
      "[I 2025-10-21 10:03:08,192] Trial 3 finished with value: 0.022049011662602425 and parameters: {'no_components': 31, 'learning_rate': 0.005517986906626521, 'loss': 'logistic'}. Best is trial 0 with value: 0.02654140256345272.\n",
      "[I 2025-10-21 10:06:24,367] Trial 4 finished with value: 0.021537689492106438 and parameters: {'no_components': 60, 'learning_rate': 0.0004695056297440149, 'loss': 'logistic'}. Best is trial 0 with value: 0.02654140256345272.\n",
      "[I 2025-10-21 10:08:37,648] Trial 5 finished with value: 0.02040361426770687 and parameters: {'no_components': 38, 'learning_rate': 0.0007124080284630054, 'loss': 'logistic'}. Best is trial 0 with value: 0.02654140256345272.\n",
      "[I 2025-10-21 10:11:59,336] Trial 6 finished with value: 0.02144373394548893 and parameters: {'no_components': 65, 'learning_rate': 0.00654803872564287, 'loss': 'logistic'}. Best is trial 0 with value: 0.02654140256345272.\n",
      "[I 2025-10-21 10:16:56,116] Trial 7 finished with value: 0.015513860620558262 and parameters: {'no_components': 100, 'learning_rate': 0.0023881413827947524, 'loss': 'logistic'}. Best is trial 0 with value: 0.02654140256345272.\n",
      "[I 2025-10-21 10:22:30,005] Trial 8 finished with value: 0.022591905668377876 and parameters: {'no_components': 100, 'learning_rate': 0.006788587253425284, 'loss': 'logistic'}. Best is trial 0 with value: 0.02654140256345272.\n",
      "[I 2025-10-21 10:26:05,513] Trial 9 finished with value: 0.02180458791553974 and parameters: {'no_components': 88, 'learning_rate': 0.0006848365688184797, 'loss': 'logistic'}. Best is trial 0 with value: 0.02654140256345272.\n",
      "[I 2025-10-21 10:28:34,032] Trial 10 finished with value: 0.032730329781770706 and parameters: {'no_components': 63, 'learning_rate': 0.00012026580535369461, 'loss': 'logistic'}. Best is trial 10 with value: 0.032730329781770706.\n",
      "[I 2025-10-21 10:30:41,071] Trial 11 finished with value: 0.03260047361254692 and parameters: {'no_components': 61, 'learning_rate': 0.00010147743810271965, 'loss': 'logistic'}. Best is trial 10 with value: 0.032730329781770706.\n",
      "[I 2025-10-21 10:33:16,196] Trial 12 finished with value: 0.03446480259299278 and parameters: {'no_components': 77, 'learning_rate': 0.00010027576106954592, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n",
      "[I 2025-10-21 10:35:50,716] Trial 13 finished with value: 0.03002891130745411 and parameters: {'no_components': 77, 'learning_rate': 0.00012565594467059442, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n",
      "[I 2025-10-21 10:38:16,278] Trial 14 finished with value: 0.02075047977268696 and parameters: {'no_components': 74, 'learning_rate': 0.0002762567152606728, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n",
      "[I 2025-10-21 10:40:55,096] Trial 15 finished with value: 0.021836360916495323 and parameters: {'no_components': 81, 'learning_rate': 0.04636066483129594, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n",
      "[I 2025-10-21 10:42:32,818] Trial 16 finished with value: 0.02160830982029438 and parameters: {'no_components': 49, 'learning_rate': 0.00026854449350727694, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n",
      "[I 2025-10-21 10:44:50,444] Trial 17 finished with value: 0.024043701589107513 and parameters: {'no_components': 70, 'learning_rate': 0.019708125518665232, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n",
      "[I 2025-10-21 10:47:38,097] Trial 18 finished with value: 0.018366260454058647 and parameters: {'no_components': 86, 'learning_rate': 0.0013735653423825, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n",
      "[I 2025-10-21 10:49:21,799] Trial 19 finished with value: 0.03433641418814659 and parameters: {'no_components': 52, 'learning_rate': 0.00018325573693161695, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n",
      "[I 2025-10-21 10:50:58,967] Trial 20 finished with value: 0.021396221593022346 and parameters: {'no_components': 49, 'learning_rate': 0.0003947684276090516, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n",
      "[I 2025-10-21 10:52:43,321] Trial 21 finished with value: 0.03186550363898277 and parameters: {'no_components': 53, 'learning_rate': 0.000146280845848681, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n",
      "[I 2025-10-21 10:54:55,081] Trial 22 finished with value: 0.03224676847457886 and parameters: {'no_components': 67, 'learning_rate': 0.00010100743525611871, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n",
      "[I 2025-10-21 10:58:16,074] Trial 23 finished with value: 0.031184570863842964 and parameters: {'no_components': 90, 'learning_rate': 0.00018955093074636954, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n",
      "[I 2025-10-21 11:01:02,714] Trial 24 finished with value: 0.021915873512625694 and parameters: {'no_components': 43, 'learning_rate': 0.0004192129042516094, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n",
      "[I 2025-10-21 11:04:57,188] Trial 25 finished with value: 0.01985102705657482 and parameters: {'no_components': 72, 'learning_rate': 0.0008271763587228796, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n",
      "[I 2025-10-21 11:09:01,789] Trial 26 finished with value: 0.022473618388175964 and parameters: {'no_components': 81, 'learning_rate': 0.0002109377871678934, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n",
      "[I 2025-10-21 11:12:06,134] Trial 27 finished with value: 0.021317550912499428 and parameters: {'no_components': 63, 'learning_rate': 0.0003244557430406844, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n",
      "[I 2025-10-21 11:13:58,331] Trial 28 finished with value: 0.031112035736441612 and parameters: {'no_components': 33, 'learning_rate': 0.00016004396920236052, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n",
      "[I 2025-10-21 11:16:39,550] Trial 29 finished with value: 0.030948767438530922 and parameters: {'no_components': 55, 'learning_rate': 0.00019157956488790782, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n",
      "[I 2025-10-21 11:19:44,556] Trial 30 finished with value: 0.020396003499627113 and parameters: {'no_components': 57, 'learning_rate': 0.0011840934355324573, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n",
      "[I 2025-10-21 11:23:01,131] Trial 31 finished with value: 0.03191852942109108 and parameters: {'no_components': 60, 'learning_rate': 0.0001133248881216988, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n",
      "[I 2025-10-21 11:25:46,750] Trial 32 finished with value: 0.03179819881916046 and parameters: {'no_components': 51, 'learning_rate': 0.00011193042721786481, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n",
      "[I 2025-10-21 11:27:36,609] Trial 33 finished with value: 0.03372298926115036 and parameters: {'no_components': 45, 'learning_rate': 0.00010156090716295578, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n",
      "[I 2025-10-21 11:28:58,615] Trial 34 finished with value: 0.02310541272163391 and parameters: {'no_components': 44, 'learning_rate': 0.00026260386604747205, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n",
      "[I 2025-10-21 11:29:47,362] Trial 35 finished with value: 0.02116757072508335 and parameters: {'no_components': 25, 'learning_rate': 0.0005235753403668263, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n",
      "[I 2025-10-21 11:31:10,510] Trial 36 finished with value: 0.032141122967004776 and parameters: {'no_components': 40, 'learning_rate': 0.00017472229549663737, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n",
      "[I 2025-10-21 11:32:47,398] Trial 37 finished with value: 0.02210414409637451 and parameters: {'no_components': 46, 'learning_rate': 0.010758308311969202, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n",
      "[I 2025-10-21 11:34:06,075] Trial 38 finished with value: 0.023662840947508812 and parameters: {'no_components': 35, 'learning_rate': 0.002593902079149688, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n",
      "[I 2025-10-21 11:36:37,242] Trial 39 finished with value: 0.020198747515678406 and parameters: {'no_components': 67, 'learning_rate': 0.0005350840867577574, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n",
      "[I 2025-10-21 11:38:47,105] Trial 40 finished with value: 0.022505810484290123 and parameters: {'no_components': 57, 'learning_rate': 0.08270250167255264, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n",
      "[I 2025-10-21 11:41:01,870] Trial 41 finished with value: 0.03274507820606232 and parameters: {'no_components': 59, 'learning_rate': 0.00010537819875239008, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n",
      "[I 2025-10-21 11:42:42,342] Trial 42 finished with value: 0.030534891411662102 and parameters: {'no_components': 48, 'learning_rate': 0.00013729870712193753, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n",
      "[I 2025-10-21 11:44:03,049] Trial 43 finished with value: 0.02458641119301319 and parameters: {'no_components': 38, 'learning_rate': 0.00020724324726558306, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n",
      "[I 2025-10-21 11:45:48,287] Trial 44 finished with value: 0.022033387795090675 and parameters: {'no_components': 53, 'learning_rate': 0.00032579014004621243, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n",
      "[I 2025-10-21 11:46:43,434] Trial 45 finished with value: 0.03155316784977913 and parameters: {'no_components': 28, 'learning_rate': 0.00015730402751537454, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n",
      "[I 2025-10-21 11:48:41,774] Trial 46 finished with value: 0.02243453823029995 and parameters: {'no_components': 64, 'learning_rate': 0.0002455715205575754, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n",
      "[I 2025-10-21 11:51:08,709] Trial 47 finished with value: 0.015929069370031357 and parameters: {'no_components': 77, 'learning_rate': 0.004419107839699509, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n",
      "[I 2025-10-21 11:54:15,661] Trial 48 finished with value: 0.031528424471616745 and parameters: {'no_components': 94, 'learning_rate': 0.00013318832088953967, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n",
      "[I 2025-10-21 11:56:22,553] Trial 49 finished with value: 0.0319167785346508 and parameters: {'no_components': 68, 'learning_rate': 0.00010366701829287617, 'loss': 'logistic'}. Best is trial 12 with value: 0.03446480259299278.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      "{'no_components': 77, 'learning_rate': 0.00010027576106954592, 'loss': 'logistic'}\n"
     ]
    }
   ],
   "source": [
    "# Run the optimization with Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best parameters found:\")\n",
    "print(study.best_params)\n",
    "\n",
    "# Save the best parameters to a JSON file\n",
    "os.makedirs(\"../experiments\", exist_ok=True)\n",
    "with open(\"../experiments/lightfm_best_params.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"best_params\": study.best_params,\n",
    "            \"best_precision_at_5\": study.best_value\n",
    "        },\n",
    "        f,\n",
    "        indent=4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec48de31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x224eee250f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the best parameters from the JSON file\n",
    "with open(\"../experiments/lightfm_best_params.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    best = json.load(f)\n",
    "best_params = best[\"best_params\"]\n",
    "\n",
    "# Instantiate and train the final model with the best parameters\n",
    "# and interactions from the entire training set\n",
    "final_model = LightFM(\n",
    "    no_components=best_params[\"no_components\"],\n",
    "    learning_rate=best_params[\"learning_rate\"],\n",
    "    loss=best_params[\"loss\"]\n",
    ")\n",
    "final_model.fit(\n",
    "    interactions,\n",
    "    user_features=user_features,\n",
    "    item_features=item_features,\n",
    "    epochs=20,\n",
    "    num_threads=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbdc4770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the 50 most relevant users for each item in the test set\n",
    "\n",
    "# Load all the user IDs\n",
    "user_ids = list(user_ids)\n",
    "\n",
    "# Build the item features matrix for the test set\n",
    "test_item_features_matrix = dataset.build_item_features(test_item_features)\n",
    "\n",
    "# Generate recommendations for each test item\n",
    "# getting top 50 users for each item so its possible to compare\n",
    "# with Knowledge Graph Method results on k = 10, 20 and 50\n",
    "top_k = 50\n",
    "recommendations = {}\n",
    "\n",
    "# Mapeamento reverso do índice interno para o ID real do usuário\n",
    "user_id_map = {v: k for k, v in dataset.mapping()[0].items()}\n",
    "\n",
    "for item_id in test_item_ids:\n",
    "    # Índice interno do item de teste\n",
    "    item_internal_idx = dataset.mapping()[2][item_id]\n",
    "    # Score para todos os usuários para este item\n",
    "    scores = final_model.predict(\n",
    "        user_ids=np.arange(len(user_ids)),\n",
    "        item_ids=np.repeat(item_internal_idx, len(user_ids)),\n",
    "        user_features=user_features,\n",
    "        item_features=test_item_features_matrix\n",
    "    )\n",
    "    # Top 50 usuários (índices ordenados por score decrescente)\n",
    "    top_users_idx = np.argsort(-scores)[:top_k]\n",
    "    # IDs reais dos usuários\n",
    "    top_users = [user_ids[i] for i in top_users_idx]\n",
    "    recommendations[item_id] = top_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f7fc643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision@10 por item:\n",
      "[0.1, 0.0, 0.1, 0.2, 0.3, 0.1, 0.1, 0.1, 0.2, 0.3, 0.3, 0.0, 0.0, 0.2, 0.1, 0.4, 0.3, 0.1, 0.0, 0.4, 0.1, 0.3, 0.1, 0.4, 0.4, 0.0, 0.1, 0.2, 0.1, 0.0]\n",
      "NDCG@10 por item:\n",
      "[np.float64(0.13886244387355454), np.float64(0.0), np.float64(0.07336392209936005), np.float64(0.21222636597291458), np.float64(0.2973694836145356), np.float64(0.22009176629808017), np.float64(0.22009176629808017), np.float64(0.07336392209936005), np.float64(0.21726071285222986), np.float64(0.2685529228900211), np.float64(0.2735872697693364), np.float64(0.0), np.float64(0.0), np.float64(0.21222636597291458), np.float64(0.11004588314904008), np.float64(0.40741536676357565), np.float64(0.3340514446642156), np.float64(0.07336392209936005), np.float64(0.0), np.float64(0.3757677525932109), np.float64(0.06362078819895171), np.float64(0.2758471541718663), np.float64(0.07336392209936005), np.float64(0.5173633627401372), np.float64(0.5231737964779628), np.float64(0.0), np.float64(0.11004588314904008), np.float64(0.2863459897524692), np.float64(0.22009176629808017), np.float64(0.0)]\n",
      "\n",
      "Precision@20 por item:\n",
      "[0.2, 0.0, 0.15, 0.2, 0.2, 0.1, 0.1, 0.15, 0.25, 0.25, 0.25, 0.05, 0.0, 0.3, 0.15, 0.45, 0.3, 0.05, 0.05, 0.3, 0.05, 0.2, 0.05, 0.4, 0.4, 0.1, 0.15, 0.15, 0.1, 0.1]\n",
      "NDCG@20 por item:\n",
      "[np.float64(0.1930620390390707), np.float64(0.0), np.float64(0.11845314056529317), np.float64(0.20405243092841763), np.float64(0.2266627278520837), np.float64(0.17437833078197715), np.float64(0.17490501020123428), np.float64(0.11443514372507416), np.float64(0.24453612504122593), np.float64(0.24040375161388872), np.float64(0.24365275471062), np.float64(0.03233829114831982), np.float64(0.0), np.float64(0.27447169117293896), np.float64(0.13622328153272548), np.float64(0.4424588661479067), np.float64(0.3155393295069234), np.float64(0.04734667987788577), np.float64(0.03475017269886857), np.float64(0.3136146988152395), np.float64(0.04105877938688906), np.float64(0.2135327563765326), np.float64(0.04734667987788577), np.float64(0.4754217619704539), np.float64(0.47659404756084595), np.float64(0.06708846384718839), np.float64(0.14307694288214187), np.float64(0.2171366432970087), np.float64(0.17437833078197715), np.float64(0.0711064606874074)]\n",
      "\n",
      "Precision@50 por item:\n",
      "[0.24, 0.08, 0.24, 0.2, 0.2, 0.18, 0.1, 0.24, 0.36, 0.3, 0.24, 0.12, 0.1, 0.3, 0.12, 0.48, 0.2, 0.12, 0.16, 0.3, 0.12, 0.22, 0.12, 0.5, 0.46, 0.16, 0.26, 0.16, 0.1, 0.14]\n",
      "NDCG@50 por item:\n",
      "[np.float64(0.22380634081601208), np.float64(0.06085817747223398), np.float64(0.19990748195975938), np.float64(0.19978029025934602), np.float64(0.2162978797670039), np.float64(0.2012681146857373), np.float64(0.14061992286578895), np.float64(0.19659745620360541), np.float64(0.32710057503232853), np.float64(0.28476704873434655), np.float64(0.2384148119729822), np.float64(0.09491255248025589), np.float64(0.07458477389836145), np.float64(0.28690679513437073), np.float64(0.11778552906223853), np.float64(0.4675451302888097), np.float64(0.23240520231253645), np.float64(0.10288385785120392), np.float64(0.12712263321526143), np.float64(0.30721606757842457), np.float64(0.10030526197387649), np.float64(0.22298858037462752), np.float64(0.10088215951255598), np.float64(0.5175125013413779), np.float64(0.48392483167413786), np.float64(0.12167060672276356), np.float64(0.22494154895084142), np.float64(0.19425316788974017), np.float64(0.139809206155876), np.float64(0.11648672797813488)]\n"
     ]
    }
   ],
   "source": [
    "# Calculate precision@k and ndcg@k for k = 10, 20, 50\n",
    "def precision_at_k(recommended, relevant, k):\n",
    "    recommended_k = recommended[:k]\n",
    "    relevant_set = set(relevant)\n",
    "    hits = sum([1 for user in recommended_k if user in relevant_set])\n",
    "    return hits / k\n",
    "\n",
    "def dcg_at_k(recommended, relevant, k):\n",
    "    recommended_k = recommended[:k]\n",
    "    relevant_set = set(relevant)\n",
    "    return sum([1 / np.log2(idx + 2) if user in relevant_set else 0\n",
    "                for idx, user in enumerate(recommended_k)])\n",
    "\n",
    "def ndcg_at_k(recommended, relevant, k):\n",
    "    dcg = dcg_at_k(recommended, relevant, k)\n",
    "    ideal_dcg = sum([1 / np.log2(idx + 2) for idx in range(min(len(relevant), k))])\n",
    "    return dcg / ideal_dcg if ideal_dcg > 0 else 0.0\n",
    "\n",
    "ks = [10, 20, 50]\n",
    "precision_scores = {k: [] for k in ks}\n",
    "ndcg_scores = {k: [] for k in ks}\n",
    "\n",
    "# Crie um dicionário: item_id -> lista de usuários relevantes (do test_interactions_df)\n",
    "test_relevant = (\n",
    "    test_interactions_df.groupby('item_id')['user_id']\n",
    "    .apply(list)\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "for item_id, recommended_users in recommendations.items():\n",
    "    # Converta ambos para string para garantir a comparação correta\n",
    "    relevant_users = [str(u) for u in test_relevant.get(int(item_id), [])]\n",
    "    recommended_users = [str(u) for u in recommended_users]\n",
    "    for k in ks:\n",
    "        prec = precision_at_k(recommended_users, relevant_users, k)\n",
    "        ndcg = ndcg_at_k(recommended_users, relevant_users, k)\n",
    "        precision_scores[k].append(prec)\n",
    "        ndcg_scores[k].append(ndcg)\n",
    "\n",
    "for k in ks:\n",
    "    print(f\"\\nPrecision@{k} por item:\")\n",
    "    print(precision_scores[k])  # Lista com 30 valores\n",
    "\n",
    "    print(f\"NDCG@{k} por item:\")\n",
    "    print(ndcg_scores[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa913dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10: 0.1667\n",
      "NDCG@10: 0.1859\n",
      "Precision@20: 0.1733\n",
      "NDCG@20: 0.1819\n",
      "Precision@50: 0.2173\n",
      "NDCG@50: 0.2108\n"
     ]
    }
   ],
   "source": [
    "# Média para cada k\n",
    "for k in ks:\n",
    "    print(f\"Precision@{k}: {np.mean(precision_scores[k]):.4f}\")\n",
    "    print(f\"NDCG@{k}: {np.mean(ndcg_scores[k]):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc306361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar listas completas de métricas por item\n",
    "results = {\n",
    "    **{f\"precision@{k}\": precision_scores[k] for k in ks},\n",
    "    **{f\"ndcg@{k}\": ndcg_scores[k] for k in ks}\n",
    "}\n",
    "\n",
    "with open(\"../experiments/lightfm_final_metrics.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kgenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
